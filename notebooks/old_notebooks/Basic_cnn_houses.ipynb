{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "from keras.backend import clear_session\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pickle\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import decode_predictions\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_data = '_smaller' #choice between '', '_smaller', '_smallest'\n",
    "\n",
    "size_image = 256 # choice between 128 and 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center = False,\n",
    "                             preprocessing_function=preprocess_input,\n",
    "                            rescale = 1/256)\n",
    "\n",
    "#import data\n",
    "train_in = datagen.flow_from_directory('../../data/Building_labeled_train_data'+str(which_data),\n",
    "#                                       color_mode=\"rgb\",\n",
    "                                       target_size = (size_image, size_image),\n",
    "#                                        batch_size=32,\n",
    "                                       class_mode=\"categorical\",\n",
    "                                       shuffle=True,\n",
    "                                       seed=42)\n",
    "\n",
    "test_in = datagen.flow_from_directory('../../data/Building_labeled_test_data'+str(which_data),\n",
    "#                                       color_mode=\"rgb\",\n",
    "                                      target_size = (size_image, size_image),\n",
    "#                                        batch_size=32,\n",
    "                                       class_mode=\"categorical\",\n",
    "                                       shuffle=True,\n",
    "                                       seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_in.next()\n",
    "X_test, y_test = test_in.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('X_train: ', X_train.shape,\n",
    "       '\\ny_train: ', y_train.shape,\n",
    "       '\\nX_test: ', X_test.shape,\n",
    "       '\\ny_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_in.next()\n",
    "for i in range(0,5):\n",
    "    image = x[i] \n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train[0].shape #the input shape should not include batch size\n",
    "n_classes = y_train[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cnn_model(input_shape):\n",
    "    X_input = Input((input_shape))\n",
    "    print('made input layer: ', X_input.shape)\n",
    "    \n",
    "    #conv\n",
    "    X = Conv2D(16, (3,3), name='conv0')(X_input)\n",
    "    print('after conv2d: ', X.shape)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    print('after BN: ', X.shape)\n",
    "    X = Activation('relu')(X)\n",
    "    print('after activation: ', X.shape)\n",
    "    X = MaxPooling2D((2), name='max_pool0')(X)\n",
    "    print('after maxpool2d: ', X.shape)\n",
    "    \n",
    "    X = Conv2D(25, (6,6), name='conv1')(X)\n",
    "    print('after conv2d: ', X.shape)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    print('after BN: ', X.shape)\n",
    "    X = Activation('relu')(X)\n",
    "    print('after activation: ', X.shape)\n",
    "    X = MaxPooling2D((2), name='max_pool1')(X)\n",
    "    print('after maxpool2d: ', X.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    print('after dropout: ', X.shape)\n",
    "    \n",
    "    #rest\n",
    "    X = Flatten()(X)\n",
    "    print('after flatten: ', X.shape)\n",
    "    \n",
    "    #add one dense layer\n",
    "    X = Dense(150, activation='relu', name='dense')(X)\n",
    "    print('after dense: ', X.shape)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    #final prediction\n",
    "    X = Dense(n_classes, activation='softmax', name='final_dense')(X)\n",
    "    print('after dense: ', X.shape)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X,  name='basic_cnn')\n",
    "    #here we are only building the model, that starting from X_input leads to (the last\n",
    "    #X) through all the layers\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = basic_cnn_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='accuracy', min_delta=0.01, patience=10, verbose=1, mode='max',\n",
    "    baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with multiprocessing: tot time = \n",
    "#without: tot time = \n",
    "\n",
    "\n",
    "# history = cnn_model.fit(X_train_sub, y_train_onehot_sub, batch_size=32, epochs=300,\n",
    "#              validation_split=0.2)\n",
    "\n",
    "# train_set = train_in[:train_in.s]\n",
    "\n",
    "\n",
    "history = cnn_model.fit_generator(train_in, epochs=5, validation_data=test_in, \n",
    "                                  callbacks=[early_stop],\n",
    "                                 validation_freq=1,\n",
    "                                 use_multiprocessing=True\n",
    "                                 )\n",
    "\n",
    "\n",
    "# history = cnn_model.fit_generator(train_in, epochs=5, \n",
    "#                                   callbacks=[early_stop], \n",
    "#                                   use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "### but this trains only on 1 batch of the data from the generator\n",
    "\n",
    "# history = cnn_model.fit(X_train, y_train, epochs=5, \n",
    "#                         callbacks=[early_stop],\n",
    "# #                         val_split=0.2,\n",
    "#                        use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print('initial accuracy on train: ',  cnn_model.history.history['accuracy'][0])\n",
    "print('final accuracy on train: ',  cnn_model.history.history['accuracy'][-1])\n",
    "\n",
    "print('initial accuracy on val: ',  cnn_model.history.history['val_accuracy'][0])\n",
    "print('final accuracy on val: ',  cnn_model.history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic model (10 epochs): \n",
    "tr 0.73 -> 0.86\n",
    "val 0.25 -> 0.22\n",
    "\n",
    "basic model (20 epochs):\n",
    "tr 0.86 -> 0.92\n",
    "val 0.23 -> 0.28\n",
    "\n",
    "\n",
    "adding 1 more conv layer and 1 more dense layer (20 epochs):\n",
    "seems not to improve (stopped)\n",
    "\n",
    "with pretrained mobilenet (10 epochs):\n",
    "tr: 0.24 -> 0.41\n",
    "val: 0.28 -> 0.33\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some notes (with toy data)\n",
    "\n",
    "* inital configuration:\n",
    "conv2d\n",
    "batchnormalization\n",
    "activation\n",
    "maxpooling\n",
    "flatten\n",
    "dense\n",
    "\n",
    "gave training accuracy 0.18 (1st epoch) -> 1 (last epoch), val accuracy 0.24 -> 0.37\n",
    "\n",
    "So the train goes well but not the validation: need to regularize and/or have more data\n",
    "\n",
    "* adding a dropout (after maxpooling): not much improvement\n",
    "* adding dropout AND training on more data: tr: 0.17 -> 0.98, val 0.15 -> 0.4\n",
    "* without dropout but more data: tr 0.2 -> 1, val 0.25 -> 0.42\n",
    "\n",
    "the higher dropout the better improvement (0.5 better than 0.2)\n",
    "\n",
    "* adding a dense layer before the final layer: not improved\n",
    "\n",
    "* adding another conv2d layer (with batch, act, maxpooling): tr same, val 0.16 -> 0.4\n",
    "but the val loss behaves better\n",
    "\n",
    "* with more conv filters: tr same, val 0.12 -> 0.42\n",
    "\n",
    "* with larger batch size: tr same, val 0.13 -> 0.43\n",
    "\n",
    "* with more epochs: tr same, val 0.12 -> 0.46\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cnn_model.evaluate(X_test_sub, y_test_onehot_sub, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_vgg128 = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model_vgg256 = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import few models\n",
    "\n",
    "size_image=256\n",
    "# base_model_mobilenet = MobileNet(weights='imagenet', include_top=False, input_shape=(size_image, size_image, 3))\n",
    "\n",
    "base_model_inceptionv3 = InceptionV3(weights='imagenet', \n",
    "                                     include_top=False, \n",
    "                                     input_shape=(size_image, size_image, 3))\n",
    "\n",
    "base_model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(size_image, size_image, 3))\n",
    "\n",
    "base_model_xception = Xception(weights='imagenet', include_top=False, input_shape=(size_image, size_image, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = base_model_vgg256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if I need to save it to use it on the cluster\n",
    "\n",
    "models_list = [base_model_vgg128, base_model_vgg256, base_model_inceptionv3, \n",
    "               base_model_vgg19, base_model_xception]\n",
    "models_names = ['base_model_vgg128', 'base_model_vgg256', 'base_model_inceptionv3_256',\n",
    "               'base_model_vgg19_256', 'base_model_xception_256']\n",
    "\n",
    "for model, model_name in zip(models_list, models_names):\n",
    "    with open(f'{model_name}.pickle', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_model_inceptionv3_256.pickle', 'wb') as f:\n",
    "        pickle.dump(base_model_inceptionv3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add last layers\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(n_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='loss', \n",
    "    min_delta=0.01, \n",
    "    patience=15, \n",
    "    verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        self.accuracy = []\n",
    "        self.val_accuracy = []\n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.accuracy.append(logs.get('acc'))\n",
    "        self.val_accuracy.append(logs.get('val_acc'))\n",
    "        self.i += 1\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        ax1.set_yscale('log')\n",
    "        ax1.plot(self.x, self.loss, label=\"loss\")\n",
    "        ax1.plot(self.x, self.val_loss, label=\"val_loss\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(self.x, self.accuracy, label=\"accuracy\")\n",
    "        ax2.plot(self.x, self.val_accuracy, label=\"validation accuracy\")\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.show();\n",
    "        \n",
    "plot = PlotLearning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name, layer.trainable)\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "mn_history = model.fit_generator(train_in, epochs=5,\n",
    "#                                  validation_data=test_in, \n",
    "                                  callbacks=[early_stop, plot, ],\n",
    "#                                  validation_freq=1,\n",
    "                                 use_multiprocessing=True\n",
    "                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('initial accuracy on train: ', mn_history.history['accuracy'][0])\n",
    "print('final accuracy on train: ', mn_history.history['accuracy'][-1])\n",
    "\n",
    "print('initial accuracy on val: ', mn_history.history['val_accuracy'][0])\n",
    "print('final accuracy on val: ', mn_history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#_inception v2 resnet\n",
    "#_5 epochs\n",
    "#_128x128\n",
    "initial accuracy on train:  0.2320909\n",
    "final accuracy on train:  0.36954546\n",
    "initial accuracy on val:  0.26877760887145996\n",
    "final accuracy on val:  0.2989690601825714\n",
    "\n",
    "\n",
    "#_inception v2 resnet\n",
    "#_5 epochs\n",
    "#_256x256\n",
    "initial accuracy on train:  0.28054544\n",
    "final accuracy on train:  0.4851818\n",
    "initial accuracy on val:  0.3343151807785034\n",
    "final accuracy on val:  0.38954344391822815\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(mn_history.history['accuracy'])\n",
    "plt.plot(mn_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(mn_history.history['loss'])\n",
    "plt.plot(mn_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
