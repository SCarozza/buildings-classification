{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "#just to start with mnist\n",
    "\n",
    "(X_train1, y_train1), (X_test1, y_test1) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colorful toy set\n",
    "(X_train2, y_train2), (X_test2, y_test2) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use the colorful toy set\n",
    "X_train = X_train2\n",
    "y_train = y_train2\n",
    "X_test = X_test2\n",
    "y_test = y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('X_train: ', X_train.shape,\n",
    "       '\\ny_train: ', y_train.shape,\n",
    "       '\\nX_test: ', X_test.shape,\n",
    "       '\\ny_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plt.imshow(random.choice(X_train), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale pixels, ohe\n",
    "\n",
    "X_train = X_train.astype('float') / 255\n",
    "X_test = X_test.astype('float') / 255\n",
    "\n",
    "y_train_onehot, y_test_onehot = to_categorical(y_train), to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('X_train: ', X_train.shape,\n",
    "       '\\ny_train_onehot: ', y_train.shape,\n",
    "       '\\nX_test: ', X_test.shape,\n",
    "       '\\ny_test_onehot: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a subset\n",
    "# t = X_train[1][0][0][0]\n",
    "# X_train[1].shape #extract image\n",
    "# X_train[1][1][1].shape #1 pixel in the 3 colors channels\n",
    "\n",
    "X_train_sub = X_train[:3000]\n",
    "X_test_sub = X_test[:3000]\n",
    "y_train_onehot_sub = y_train_onehot[:3000]\n",
    "y_test_onehot_sub = y_test_onehot[:3000]\n",
    "\n",
    "X_train_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras import Model\n",
    "\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train_sub[0].shape #the input shape should not include batch size\n",
    "\n",
    "def basic_cnn_model(input_shape):\n",
    "    X_input = Input((input_shape))\n",
    "    print('made input layer: ', X_input.shape)\n",
    "    \n",
    "    #conv\n",
    "    X = Conv2D(16, (3,3), name='conv0')(X_input)\n",
    "    print('after conv2d: ', X.shape)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    print('after BN: ', X.shape)\n",
    "    X = Activation('relu')(X)\n",
    "    print('after activation: ', X.shape)\n",
    "    X = MaxPooling2D((2), name='max_pool0')(X)\n",
    "    print('after maxpool2d: ', X.shape)\n",
    "    \n",
    "    X = Conv2D(25, (6,6), name='conv1')(X)\n",
    "    print('after conv2d: ', X.shape)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    print('after BN: ', X.shape)\n",
    "    X = Activation('relu')(X)\n",
    "    print('after activation: ', X.shape)\n",
    "    X = MaxPooling2D((2), name='max_pool1')(X)\n",
    "    print('after maxpool2d: ', X.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    print('after dropout: ', X.shape)\n",
    "    \n",
    "    #rest\n",
    "    X = Flatten()(X)\n",
    "    print('after flatten: ', X.shape)\n",
    "    \n",
    "#     #add one dense layer\n",
    "#     X = Dense(150, activation='relu', name='dense')(X)\n",
    "#     print('after dense: ', X.shape)\n",
    "    \n",
    "#     X = Dropout(0.5)(X)\n",
    "    \n",
    "    #final prediction\n",
    "    X = Dense(10, activation='softmax', name='final_dense')(X)\n",
    "    print('after dense: ', X.shape)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X,  name='basic_cnn')\n",
    "    #here we are only building the model, that starting from X_input leads to (the last\n",
    "    #X) through all the layers\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "# clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = basic_cnn_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop = EarlyStopping(monitor='accuracy', min_delta=0.0001, patience=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to test early stop\n",
    "\n",
    "# history = cnn_model.fit(X_train_sub, y_train_onehot_sub, batch_size=32, epochs=30,\n",
    "#              validation_split=0.2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(X_train, y_train_onehot, batch_size=32, epochs=300,\n",
    "             validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('initial accuracy on train: ', history.history['accuracy'][0])\n",
    "print('final accuracy on train: ', history.history['accuracy'][-1])\n",
    "\n",
    "print('initial accuracy on val: ', history.history['val_accuracy'][0])\n",
    "print('final accuracy on val: ', history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some notes\n",
    "\n",
    "* inital configuration:\n",
    "conv2d\n",
    "batchnormalization\n",
    "activation\n",
    "maxpooling\n",
    "flatten\n",
    "dense\n",
    "\n",
    "gave training accuracy 0.18 (1st epoch) -> 1 (last epoch), val accuracy 0.24 -> 0.37\n",
    "\n",
    "So the train goes well but not the validation: need to regularize and/or have more data\n",
    "\n",
    "* adding a dropout (after maxpooling): not much improvement\n",
    "* adding dropout AND training on more data: tr: 0.17 -> 0.98, val 0.15 -> 0.4\n",
    "* without dropout but more data: tr 0.2 -> 1, val 0.25 -> 0.42\n",
    "\n",
    "the higher dropout the better improvement (0.5 better than 0.2)\n",
    "\n",
    "* adding a dense layer before the final layer: not improved\n",
    "\n",
    "* adding another conv2d layer (with batch, act, maxpooling): tr same, val 0.16 -> 0.4\n",
    "but the val loss behaves better\n",
    "\n",
    "* with more conv filters: tr same, val 0.12 -> 0.42\n",
    "\n",
    "* with larger batch size: tr same, val 0.13 -> 0.43\n",
    "\n",
    "* with more epochs: tr same, val 0.12 -> 0.46\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cnn_model.evaluate(X_test_sub, y_test_onehot_sub, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import decode_predictions\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(weights='imagenet') \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = InceptionV3(weights='imagenet') \n",
    "# model.summary()\n",
    "\n",
    "model = VGG16(weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #just testing if it works on a test image\n",
    "\n",
    "# from keras.preprocessing import image\n",
    "# import numpy as np\n",
    "# from pprint import pprint\n",
    "\n",
    "# img_path = '../../data/scorpion.jpg'\n",
    "\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "# preds = decode_predictions(model.predict(x), top=5)[0]\n",
    "# preds = [(x[1], x[2]) for x in preds]\n",
    "# pprint(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "#inceptionV3 cannot use images smaller than 75x75\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "#                  metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_sub, y_train_onehot_sub, batch_size=32, epochs=100,\n",
    "             validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:19]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[19:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "mn_history = model.fit(X_train_sub, y_train_onehot_sub, batch_size=32, epochs=200,\n",
    "             validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mn_history = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('initial accuracy on train: ', mn_history.history['accuracy'][0])\n",
    "print('final accuracy on train: ', mn_history.history['accuracy'][-1])\n",
    "\n",
    "print('initial accuracy on val: ', mn_history.history['val_accuracy'][0])\n",
    "print('final accuracy on val: ', mn_history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(mn_history.history['accuracy'])\n",
    "plt.plot(mn_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(mn_history.history['loss'])\n",
    "plt.plot(mn_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
